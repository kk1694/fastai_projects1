{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_VIxfXXIm5w"
   },
   "source": [
    "# Building a Joke Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "Run on whole training data.\n",
    "\n",
    "Use valiation set to optimize parameters (such as # of activations)\n",
    "\n",
    "Put model on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsi3e859IUvX"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "0a7ctn0OOHkC",
    "outputId": "d34ff45d-1748-45cb-e83b-abb9f2d307f7"
   },
   "outputs": [],
   "source": [
    "# Only needed on google colab\n",
    "!pip install xlrd\n",
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_kGXWnSImGq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import ipdb\n",
    "\n",
    "import joke_utils\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/jester/'\n",
    "\n",
    "test_probs = (0.1, 0.2, 0.05)  # numbers for new users, new jokes, existing users & jokes\n",
    "valid_prob = 0.05\n",
    "\n",
    "bs = 32  # mini-batch size\n",
    "\n",
    "gauge_set = [7, 8, 13, 15, 16, 17, 18, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vb0tJNwUIlx7"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "8t5I8KEUM0nd",
    "outputId": "d11e3be8-d791-4b27-fb58-a8b2bc71c096"
   },
   "outputs": [],
   "source": [
    "!wget http://eigentaste.berkeley.edu/dataset/jester_dataset_3.zip\n",
    "!unzip jester_dataset_3.zip\n",
    "shutil.move('jesterfinal151cols.xls', PATH+'jesterfinal151cols.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Es6UzzeoNmR5"
   },
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "UkKMFpAPN21J",
    "outputId": "90c63967-75b2-473d-a0b5-a1da5529d615"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>99</td>\n",
       "      <td>-9.28125</td>\n",
       "      <td>-9.28125</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>-9.68750</td>\n",
       "      <td>99</td>\n",
       "      <td>9.93750</td>\n",
       "      <td>9.53125</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>-9.84375</td>\n",
       "      <td>99</td>\n",
       "      <td>-9.84375</td>\n",
       "      <td>-7.21875</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>6.90625</td>\n",
       "      <td>99</td>\n",
       "      <td>4.75000</td>\n",
       "      <td>-5.90625</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>99</td>\n",
       "      <td>-9.09375</td>\n",
       "      <td>-0.40625</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4        5    6        7        8    9    ...    141  \\\n",
       "0   62   99   99   99   99  0.21875   99 -9.28125 -9.28125   99  ...   99.0   \n",
       "1   34   99   99   99   99 -9.68750   99  9.93750  9.53125   99  ...   99.0   \n",
       "2   18   99   99   99   99 -9.84375   99 -9.84375 -7.21875   99  ...   99.0   \n",
       "3   82   99   99   99   99  6.90625   99  4.75000 -5.90625   99  ...   99.0   \n",
       "4   27   99   99   99   99 -0.03125   99 -9.09375 -0.40625   99  ...   99.0   \n",
       "\n",
       "    142   143   144   145   146   147   148   149   150  \n",
       "0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  \n",
       "1  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  \n",
       "2  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  \n",
       "3  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  \n",
       "4  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  99.0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat = pd.read_excel(PATH+'jesterfinal151cols.xls', header = None)\n",
    "rat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YzV6NJZlN8nP",
    "outputId": "45e2a98d-4dfa-404c-b411-d0ab0833ffcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.array(rat[gauge_set] == 99))  # Check if any rating is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlZMBrHkOg8p"
   },
   "outputs": [],
   "source": [
    "# These jokes have been removed\n",
    "rem_list = [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 20, 27, 31, 43, 51, 52, 61, 73, 80, 100, 116]\n",
    "rat.drop(rem_list, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat.fillna(value = 99, inplace=True)  #The last row has some missing values at the end -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "I0lRoGEbOoKY",
    "outputId": "a1d13e6e-465a-41c5-a349-5da8983e16ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>num_rated</th>\n",
       "      <th>joke_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>9.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.84375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>4.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.09375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  num_rated joke_id   rating\n",
       "0        0         62       7 -9.28125\n",
       "1        1         34       7  9.93750\n",
       "2        2         18       7 -9.84375\n",
       "3        3         82       7  4.75000\n",
       "4        4         27       7 -9.09375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add user ID, name column 0 (indicating the # of rated movies)\n",
    "rat['user_id'] = list(range(len(rat.index)))\n",
    "rat.rename({0:'num_rated'}, axis = 1, inplace=True)\n",
    "rat = rat.melt(id_vars=['user_id', 'num_rated'], var_name='joke_id', value_name='rating')\n",
    "rat = rat[rat['rating'] != 99]\n",
    "rat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1FXGi7V3Ox_K",
    "outputId": "f083788e-c50f-4c46-881f-275ca68289cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725737, 50691, 8, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(rat.index), rat['user_id'].max(), len(gauge_set), len(set(rat['joke_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~rat.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0o_tK6pQO5Np"
   },
   "source": [
    "Summary:\n",
    "- 50k users\n",
    "- 128 jokes, 8 are a gauge set that everyone responded to\n",
    "- 1.7 million ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat.to_pickle(PATH+'processed_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmrE1XCWO8mT"
   },
   "source": [
    "## Separate train/valid/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat = pd.read_pickle(PATH+'processed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rat.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, valid_idxs, test_idxs, tnu, tnj, tnuj = joke_utils.get_idxs(rat, gauge_set, \n",
    "                                                                        test_probs, valid_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pytorch dataset / data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_uniq = rat['user_id'].unique()\n",
    "user2idx = {o:i for i,o in enumerate(u_uniq)}\n",
    "idx2user = {i:o  for i, o in enumerate(u_uniq)}\n",
    "rat['user_id'] = rat['user_id'].apply(lambda x: user2idx[x])\n",
    "\n",
    "j_uniq = rat['joke_id'].unique()\n",
    "joke2idx = {o:i for i, o in enumerate(j_uniq)}\n",
    "idx2joke = {i:o for i, o in enumerate(j_uniq)}\n",
    "rat['joke_id'] = rat['joke_id'].apply(lambda x: joke2idx[x])\n",
    "\n",
    "n_users=int(rat['user_id'].nunique())\n",
    "n_jokes =int(rat['joke_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2Tens(df, idx=None):\n",
    "    if idx != None:\n",
    "        df = df.iloc[idx]\n",
    "    \n",
    "    x = torch.tensor(df[['user_id', 'joke_id']].values, dtype = torch.int64)\n",
    "    y = torch.tensor(df['rating'].values, dtype = torch.float32)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  #Note: take out the 10000 from training -- only used to make notebook run faster\n",
    "train_ds = TensorDataset(*conv2Tens(rat, train_idxs[:10000]))\n",
    "valid_ds = TensorDataset(*conv2Tens(rat, valid_idxs))\n",
    "test_ds = TensorDataset(*conv2Tens(rat, test_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle = True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = (-10, 10)\n",
    "\n",
    "def get_emb(ni,nf):\n",
    "    e = nn.Embedding(ni, nf)\n",
    "    e.weight.data.uniform_(0, 0.05)\n",
    "    return e\n",
    "\n",
    "class ColabSimple(nn.Module):\n",
    "    '''https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb'''\n",
    "    def __init__(self, n_user, n_joke, n_factors = 10):\n",
    "        super().__init__()        \n",
    "        (self.u, self.j, self.ub, self.jb) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_jokes, n_factors), (n_users,1), (n_jokes,1)]]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users, jokes = x[:, 0], x[:, 1]\n",
    "        u, j = self.u(users), self.j(jokes)\n",
    "        res = (u * j).sum(1)\n",
    "        res = res + self.ub(users).squeeze() + self.jb(jokes).squeeze()\n",
    "        res = torch.sigmoid(res) * (y_range[1]-y_range[0]) + y_range[0]\n",
    "        return res.view(-1, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColabSimple(\n",
      "  (u): Embedding(50692, 10)\n",
      "  (j): Embedding(128, 10)\n",
      "  (ub): Embedding(50692, 1)\n",
      "  (jb): Embedding(128, 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "assert False\n",
    "# Need to put on GPU  -- do the same for other models below!\n",
    "# model = ColabSimple(n_users, n_jokes).cuda()\n",
    "model = ColabSimple(n_users, n_jokes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    '''https://github.com/fastai/fastai_v1/blob/master/dev_nb/001a_nn_basics.ipynb'''\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    '''https://github.com/fastai/fastai_v1/blob/master/dev_nb/001a_nn_basics.ipynb'''\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Fit model to training data\n",
    "        model.train()\n",
    "        losses,nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb,yb in train_dl])\n",
    "        train_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "        \n",
    "        for xb,yb in train_dl: loss_batch(model, loss_func, xb, yb, opt)\n",
    "            \n",
    "        # Calculate loss on validation set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses,nums = zip(*[loss_batch(model, loss_func, xb, yb)\n",
    "                                for xb,yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "\n",
    "        print(f'Epoch {epoch}. Training loss: {train_loss}. Validation loss: {val_loss}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Training loss: 39.257692657470706. Validation loss: 29.778694172019136.\n",
      "Epoch 1. Training loss: 29.538735485839844. Validation loss: 29.425833557322015.\n",
      "Epoch 2. Training loss: 44.47094608764648. Validation loss: 29.64731864300534.\n"
     ]
    }
   ],
   "source": [
    "fit(3, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Neural Net with 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColabDeep(nn.Module):\n",
    "    def __init__(self, n_user, n_joke, nhs = [10], ps = [0.25], n_factors = 10, emb_ps = 0.05):\n",
    "        super().__init__() \n",
    "        \n",
    "        assert len(nhs) > 0\n",
    "        assert len(nhs) == len(ps)\n",
    "        \n",
    "        (self.u, self.j) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_jokes, n_factors)]]\n",
    "        \n",
    "        self.num_hidden = len(nhs) \n",
    "        self.hidden_layers = []\n",
    "        self.drops = []\n",
    "        self.emb_drop = nn.Dropout(emb_ps)\n",
    "        \n",
    "        for i in range(self.num_hidden):\n",
    "            if i == 0:\n",
    "                self.hidden_layers.append(nn.Linear(n_factors*2, nhs[0]))\n",
    "            else:\n",
    "                self.hidden_layers.append(nn.Linear(nhs[i-1], nhs[i]))\n",
    "            self.drops.append(nn.Dropout(ps[i]))\n",
    "        \n",
    "        self.last_layer = nn.Linear(nhs[self.num_hidden - 1], 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        users, jokes = x[:, 0], x[:, 1]\n",
    "        u, j = self.u(users), self.j(jokes)\n",
    "        \n",
    "        X = self.emb_drop(torch.cat([u, j], dim = 1))\n",
    "        \n",
    "        for i in range(self.num_hidden):\n",
    "            drop = self.drops[i]\n",
    "            layer = self.hidden_layers[i]\n",
    "            X = drop(F.relu(layer(X)))\n",
    "        \n",
    "        res = self.last_layer(X)\n",
    "        res = torch.sigmoid(res) * (y_range[1]-y_range[0]) + y_range[0]\n",
    "        return res.view(-1, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ColabDeep(n_users, n_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=wd)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Training loss: 34.12640700683594. Validation loss: 33.93807824631768.\n"
     ]
    }
   ],
   "source": [
    "fit(1, model2, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ColabDeep(n_users, n_jokes, nhs = [10, 5], ps = [0.25, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Training loss: 38.935981842041016. Validation loss: 30.00822083715675.\n"
     ]
    }
   ],
   "source": [
    "fit(1, model3, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(m, dl, as_torch = False):\n",
    "    \n",
    "    m.eval()\n",
    "    preds = []\n",
    "    ys = []\n",
    "    \n",
    "    with torch.no_grad():     \n",
    "        for xb, yb in dl:\n",
    "            preds.append(m(xb))\n",
    "            ys.append(yb)\n",
    "            \n",
    "    preds = torch.cat(preds, dim = 0)\n",
    "    ys = torch.cat(ys, dim = 0)\n",
    "    \n",
    "    if ~as_torch: \n",
    "        preds = np.array(preds)\n",
    "        ys = np.array(ys)\n",
    "            \n",
    "    return preds, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targets = predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(pred, target):\n",
    "    return np.mean((pred - target)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.637838"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "joke_recommendations.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
